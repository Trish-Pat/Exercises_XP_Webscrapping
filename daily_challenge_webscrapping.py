# -*- coding: utf-8 -*-
"""Daily Challenge Webscrapping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ALoceFRLs7NDH0B3wH43osMciH-FONMf
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

url = "https://github.com/topics"
response = requests.get(url)

print(f"Status Code: {response.status_code}")

print("\nFirst 100 characters of HTML:")
print(response.text[:100])

with open('webpage.html', 'w', encoding='utf-8') as file:
    file.write(response.text)
print("\nHTML content saved to 'webpage.html'")

with open('webpage.html', 'r', encoding='utf-8') as file:
    soup = BeautifulSoup(file, 'html.parser')

topic_containers = soup.select('div.py-4.border-bottom')

titles = []
descriptions = []

for container in topic_containers:
    title_element = container.select_one('a.flex-1')
    if title_element:
        titles.append(title_element.text.strip())
    else:
        titles.append(None)

    description_element = container.select_one('p.color-fg-muted.mb-0.mt-1')
    if description_element:
        descriptions.append(description_element.text.strip())
    else:
        descriptions.append(None)


print(f"\nNumber of titles extracted: {len(titles)}")
print(f"First 3 titles: {titles[:3]}")
print(f"\nNumber of descriptions extracted: {len(descriptions)}")
print(f"First 3 descriptions: {descriptions[:3]}")

data_dict = {
    'title': titles,
    'description': descriptions
}
df = pd.DataFrame(data_dict)

print("\nDataFrame structure:")
print(f"Shape: {df.shape}")
print("\nDataFrame content:")
print(df.head())

